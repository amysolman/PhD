cr.rand = random_network(g.cr[[1]], cr.net, "Cryoconite")
w.res = rbind(sn.rand[[2]], sp.rand[[2]], sm.rand[[2]], cr.rand[[2]])
#Merge data frames to make table
#Snow
r = data.frame(AveDegree = NA, ClustCoef = sn.rand[[1]][2,2], AvePathLen = sn.rand[[1]][2,3], Density = NA, Diameter = NA, Modularity = sn.rand[[1]][2,1], Nodes = sn.net$Nodes[1], Edges = sn.net$Edges[1])
sn.tab = rbind(sn.net[,-c(1)], r)
rownames(sn.tab) <- c("Full", "Random Network Mean (SD)")
df1 <- tibble::rownames_to_column(sn.tab, "Network")
df1 = cbind(rep("Snow", 2), df1)
names(df1)[1] = "Habitat"
#Spring Ice
r = data.frame(AveDegree = NA, ClustCoef = sp.rand[[1]][2,2], AvePathLen = sp.rand[[1]][2,3], Density = NA, Diameter = NA, Modularity = sp.rand[[1]][2,1], Nodes = sp.net$Nodes[1], Edges = sp.net$Edges[1])
sp.tab = rbind(sp.net[,-c(1)], r)
rownames(sp.tab) <- c("Full", "Random Network Mean (SD)")
df2 <- tibble::rownames_to_column(sp.tab, "Network")
df2 = cbind(rep("Spring Ice", 2), df2)
names(df2)[1] = "Habitat"
#Summer Ice
r = data.frame(AveDegree = NA, ClustCoef = sm.rand[[1]][2,2], AvePathLen = sm.rand[[1]][2,3], Density = NA, Diameter = NA, Modularity = sm.rand[[1]][2,1], Nodes = sm.net$Nodes[1], Edges = sm.net$Edges[1])
sm.tab = rbind(sm.net[,-c(1)], r)
rownames(sm.tab) <- c("Full", "Random Network Mean (SD)")
df3 <- tibble::rownames_to_column(sm.tab, "Network")
df3 = cbind(rep("Summer Ice", 2), df3)
names(df3)[1] = "Habitat"
#Cryoconite
r = data.frame(AveDegree = NA, ClustCoef = cr.rand[[1]][2,2], AvePathLen = cr.rand[[1]][2,3], Density = NA, Diameter = NA, Modularity = cr.rand[[1]][2,1], Nodes = cr.net$Nodes[1], Edges = cr.net$Edges[1])
cr.tab = rbind(cr.net[,-c(1)], r)
rownames(cr.tab) <- c("Full", "Random Network Mean (SD)")
df4 <- tibble::rownames_to_column(cr.tab, "Network")
df4 = cbind(rep("Cryoconite", 2), df4)
names(df4)[1] = "Habitat"
final.net.df = rbind(df1, df2, df3, df4)
#add edge/node ratio
final.net.df$EdgeNodeRatio = round(as.numeric(final.net.df$Edges)/as.numeric(final.net.df$Nodes), 3)
#export dataframe
write.csv(final.net.df, "../results/network-properties.csv")
#Are differences between the random networks and real networks significant?
rand_real_sig_dif = rbind(sn.rand[[2]], sp.rand[[2]], sm.rand[[2]], cr.rand[[2]])
write.csv(rand_real_sig_dif, "../results/wilcoxon-rand-real-networks.csv")
#Script breakdown
#3. Scale-free characteristics analysis
# Function for finding if our network exhibits scale-free characteristics
# Code taken from http://chengjun.github.io/web_data_analysis/demo2_simulate_networks/
scale_free_characteristics <- function(g, habitat){
cor_g <- g
# 1) power law distribution function
fit_power_law = function(g, network) {
set.seed(666)
# calculate degree
d = degree(g, mode = "all")
dd = degree.distribution(g, mode = "all", cumulative = FALSE)
degree = 1:max(d)
probability = dd[-1]
# delete blank values
nonzero.position = which(probability != 0)
probability = probability[nonzero.position]
degree = degree[nonzero.position]
reg = lm(log(probability) ~ log(degree))
cozf = coef(reg)
power.law.fit = function(x) exp(cozf[[1]] + cozf[[2]] * log(x))
alpha = -cozf[[2]]
R.square = summary(reg)$r.squared
res.list = list(probability, degree, cozf, d, alpha, R.square)
return(res.list)
}
#2) generate scale-free network
g.big.ba = barabasi.game(gorder(cor_g))
#3) generate random network
g.big.er = erdos.renyi.game(gorder(cor_g), 0.1)
#4) Get the info for plotting
#true network
real.res = fit_power_law(cor_g, "real")
power.law.fit1 = function(x) exp(real.res[[3]][[1]] + real.res[[3]][[2]] * log(x))
#scale-free network
scale.res = fit_power_law(g.big.ba, "scale-free")
power.law.fit2 = function(x) exp(scale.res[[3]][[1]] + scale.res[[3]][[2]] * log(x))
#random network
random.res = fit_power_law(g.big.er, "random")
power.law.fit3 = function(x) exp(random.res[[3]][[1]] + random.res[[3]][[2]] * log(x))
#plot
pdf(paste0("../results/", habitat, "power-law-model-fits.pdf"), width=10, height=6)
par(mfrow=c(1,3), mai = c(0.6, 0.6, 0.4, 0.1))
plot(real.res[[1]] ~ real.res[[2]], log = "xy", xlab = "Degree (log)", ylab = "Probability (log)",
col = 1, main = "A", cex.lab=1.5, cex.axis=1.5, cex.main=3)
curve(power.law.fit1, col = "red", add = T, n = length(real.res[[4]]))
text(cex=1.6, x=min(real.res[[2]]), y=max(real.res[[1]]), adj = 0, labels=paste0("R2 = ", round(real.res[[6]], 2), "  alpha = ", round(real.res[[5]], 2)))
plot(scale.res[[1]] ~ scale.res[[2]], log = "xy", xlab = "Degree (log)", ylab = "Probability (log)",
col = 1, main = "B", cex.lab=1.5, cex.axis=1.5, cex.main=3)
curve(power.law.fit2, col = "red", add = T, n = length(scale.res[[4]]))
text(cex=1.6, x=min(scale.res[[2]]), y=max(scale.res[[1]]), adj = 0,labels=paste0("R2 = ", round(scale.res[[6]], 2), "  alpha = ", round(scale.res[[5]], 2)))
plot(random.res[[1]] ~ random.res[[2]], log = "xy", xlab = "Degree (log)", ylab = "Probability (log)",
col = 1, main = "C", cex.lab=1.5, cex.axis=1.5, cex.main=3)
curve(power.law.fit3, col = "red", add = T, n = length(random.res[[4]]))
text(cex=1.6, x=min(random.res[[2]]), y=max(random.res[[1]]), adj = 0,labels=paste0("R2 = ", round(random.res[[6]], 2), "  alpha = ", round(random.res[[5]], 2)))
dev.off()
return(res.list=list(real.res[[6]], scale.res[[6]], random.res[[6]]))
}
sn.plm = scale_free_characteristics(g.sn[[1]], "Snow")
sp.plm = scale_free_characteristics(g.sp[[1]], "SpringIce")
sm.plm = scale_free_characteristics(g.sm[[1]], "SummerIce")
cr.plm = scale_free_characteristics(g.cr[[1]], "Cryoconite")
#1. Clear workspace and load packages
rm(list=ls())
graphics.off()
library(phyloseq)
library(Hmisc)
library(igraph)
library(vegan) #rarecurve function
library(dplyr) #for summarising data
library(ggpubr)
library(car) #levene test
library(plyr)
library(cowplot)
library(tibble) #rownames to column
# install.packages(
#   "microViz",
#   repos = c(davidbarnett = "https://david-barnett.r-universe.dev", getOption("repos"))
# )
library(microViz) #for tax_filter
source("00-solman-functions.R")
library(patchwork)
#Import networks
#positive and negative with negative values to absolute values for calculating topological features
g.sn1 = read.graph("../results/full-snow-network-for-calc-properties.gml", format="gml")
g.sp1 = read.graph("../results/full-springice-network-for-calc-properties.gml", format="gml")
g.sm1 = read.graph("../results/full-summerice-network-for-calc-properties.gml", format="gml")
g.cr1 = read.graph("../results/full-cryoconite-network-for-calc-properties.gml", format="gml")
#positive and negative networks
g.sn2 = read.graph("../results/positive-and-negative-snow-network.gml", format="gml")
g.sp2 = read.graph("../results/positive-and-negative-springice-network.gml", format="gml")
g.sm2 = read.graph("../results/positive-and-negative-summerice-network.gml", format="gml")
g.cr2 = read.graph("../results/positive-and-negative-cryoconite-network.gml", format="gml")
#positive only
g.sn3 = read.graph("../results/positive-snow-network.gml", format="gml")
g.sp3 = read.graph("../results/positive-springice-network.gml", format="gml")
g.sm3 = read.graph("../results/positive-summerice-network.gml", format="gml")
g.cr3 = read.graph("../results/positive-cryoconite-network.gml", format="gml")
#combine for analysis
g.sn <- list(g.sn1, g.sn2, g.sn3)
g.sp <- list(g.sp1, g.sp2, g.sp3)
g.sm <- list(g.sm1, g.sm2, g.sm3)
g.cr <- list(g.cr1, g.cr2, g.cr3)
node_level_properties <- function(g, habitat){
cor_g <- g
#create a dataframe with 5 columns and a row for each node (ASV)
df<-as.data.frame(matrix(NA,ncol=5,nrow=length(degree(cor_g))))
#make ASV IDs row names of df
rownames(df)<-names(degree(cor_g))
#name the colums the node-level topological features
colnames(df)<-c("degree","betweenness","closeness","eigenvector","habitat")
#get betweenness
btw<-betweenness(cor_g)
#get closeness centrality
cls<-closeness(cor_g)
#get eigenvector centrality
egv<-evcent(cor_g)
#put the topological features into the dataframe
df[,1]<-degree(cor_g)
df[,2]<-btw
df[,3]<-cls
df[,4]<-egv$vector
df[,5]<-habitat
return(df)
}
sn.node = node_level_properties(g.sn[[1]], "Snow")
sp.node = node_level_properties(g.sp[[1]], "Spring Ice")
sm.node = node_level_properties(g.sm[[1]], "Summer Ice")
cr.node = node_level_properties(g.cr[[1]], "Cryoconite")
View(sn.node)
#combine and export node-level properties
write(rbind(sn.node, sp.node, sm, node, cr.node), "../results/node-properties.csv")
#combine and export node-level properties
write(rbind(sn.node, sp.node, sm.node, cr.node), "../results/node-properties.csv")
#combine and export node-level properties
write.csv(rbind(sn.node, sp.node, sm.node, cr.node), "../results/node-properties.csv")
ps = ps.f
#Script breakdown
#1. Clear workspace and load packages
#2. Load data
#3. Get abundance dataframes
#4. Merge 16S and 18S datasets
#5. Filter ASVs by percentage of samples
#6. Carry out correlation analysis
#1. Clear workspace and load packages
rm(list=ls())
graphics.off()
library(phyloseq)
library(Hmisc)
library(igraph)
library(vegan) #rarecurve function
library(dplyr) #for summarising data
library(ggpubr)
library(car) #levene test
library(plyr)
library(cowplot)
library(tibble) #rownames to column
# install.packages(
#   "microViz",
#   repos = c(davidbarnett = "https://david-barnett.r-universe.dev", getOption("repos"))
# )
library(microViz) #for tax_filter
source("00-solman-functions.R")
library(patchwork)
#get community data
#prokaryotes
ps.pro <- readRDS("../results/16S-ps-controls-removed.rds")
#eukaryotes without microfauna
ps.euk <- readRDS("../results/18S-ps-no-mm-controls-removed.rds")
#microfauna only
ps.mm <- readRDS("../results/18S-ps-mm-only-controls-removed.rds")
#remove the sample low read count samples as we did previously
#prokaryotes
ps.pro = prune_samples(sample_sums(ps.pro)>= 1900, ps.pro) #retain samples with >= num counts
ps.pro = filter_taxa(ps.pro, function(x) sum(x) >= 1, TRUE) #remove ASVs with zero counts
#eukaryotes
ps.euk = prune_samples(sample_sums(ps.euk)>= 1900, ps.euk) #retain samples with >= num counts
ps.euk = filter_taxa(ps.euk, function(x) sum(x) >= 1, TRUE) #remove ASVs with zero counts
#micrometazoans
ps.mm = prune_samples(sample_sums(ps.mm)>= 500, ps.mm) #retain samples with >= num counts
ps.mm = filter_taxa(ps.mm, function(x) sum(x) >= 1, TRUE) #remove ASVs with zero counts
#3. Merge the datasets
merge_ps <- function(ps1, ps2, ps3){
#Extract ASV tables
tab1 = data.frame(t(otu_table(ps1)), check.names = FALSE)
tab2 = data.frame(t(otu_table(ps2)), check.names = FALSE)
tab3 = data.frame(t(otu_table(ps3)), check.names = FALSE)
#sample name to column
tab1 <- tibble::rownames_to_column(tab1, "SampleID")
tab2 <- tibble::rownames_to_column(tab2, "SampleID")
tab3 <- tibble::rownames_to_column(tab3, "SampleID")
#use dplyr to join the ASV tables
full.tab <- full_join(tab1, tab2, by="SampleID")
full.tab[is.na(full.tab)] <- 0
full.tab <- full_join(full.tab, tab3, by="SampleID")
full.tab[is.na(full.tab)] <- 0
#test if this worked
ncol(tab1) + ncol(tab2) + ncol(tab3) - 3 == ncol(full.tab) - 1 #should say TRUE
#get rid of our sample ID column
full.tab <- tibble::column_to_rownames(full.tab, var="SampleID")
#combine taxa tables
full.tax = as.matrix(rbind(data.frame(tax_table(ps1)), data.frame(tax_table(ps2)), data.frame(tax_table(ps3))))
#combine metadata
meta1 = data.frame(sample_data(ps1))
meta2 = data.frame(sample_data(ps2))
meta3 = data.frame(sample_data(ps3))
#get vector of all our samples
all.samp = unique(c(meta1$SampleID, meta2$SampleID, meta3$SampleID))
#bind the rows of our metadata
full.meta = rbind(meta1[,-c(2)], meta2[,-c(2)], meta3[,-c(2)])
#remove rownames
rownames(full.meta) <- NULL
#remove duplicate rows using dplyr
full.meta2 <- full.meta %>% distinct()
#check that this has worked
all.samp == full.meta2$SampleID #should all equal TRUE
#make rownames sample ID again
rownames(full.meta2) <- full.meta2$SampleID
#make new phyloseq object
ASV = otu_table(t(full.tab), taxa_are_rows = TRUE)
TAX = tax_table(full.tax)
META = sample_data(full.meta2)
new.phylo = phyloseq(ASV, TAX, META)
return(new.phylo)
}
ps.f <- merge_ps(ps.pro, ps.euk, ps.mm)
#export combine phyloseq object
saveRDS(ps.f, "../results/combined-phylo-for-network-analysis.rds")
#Script breakdown
#1. Calculate node-level properties
#2. Get taxonomy of nodes + report
#3. Find connections between subcommunities
#4. Find differences between subcommunities
#5. Identify keystone taxa
#1. Clear workspace and load packages
rm(list=ls())
graphics.off()
library(phyloseq)
library(Hmisc)
library(igraph)
library(vegan) #rarecurve function
library(dplyr) #for summarising data
library(ggpubr)
library(car) #levene test
library(plyr)
library(cowplot)
library(tibble) #rownames to column
# install.packages(
#   "microViz",
#   repos = c(davidbarnett = "https://david-barnett.r-universe.dev", getOption("repos"))
# )
library(microViz) #for tax_filter
source("00-solman-functions.R")
library(patchwork)
#Import networks
#positive and negative with negative values to absolute values for calculating topological features
g.sn1 = read.graph("../results/full-snow-network-for-calc-properties.gml", format="gml")
g.sp1 = read.graph("../results/full-springice-network-for-calc-properties.gml", format="gml")
g.sm1 = read.graph("../results/full-summerice-network-for-calc-properties.gml", format="gml")
g.cr1 = read.graph("../results/full-cryoconite-network-for-calc-properties.gml", format="gml")
#positive and negative networks
g.sn2 = read.graph("../results/positive-and-negative-snow-network.gml", format="gml")
g.sp2 = read.graph("../results/positive-and-negative-springice-network.gml", format="gml")
g.sm2 = read.graph("../results/positive-and-negative-summerice-network.gml", format="gml")
g.cr2 = read.graph("../results/positive-and-negative-cryoconite-network.gml", format="gml")
#positive only
g.sn3 = read.graph("../results/positive-snow-network.gml", format="gml")
g.sp3 = read.graph("../results/positive-springice-network.gml", format="gml")
g.sm3 = read.graph("../results/positive-summerice-network.gml", format="gml")
g.cr3 = read.graph("../results/positive-cryoconite-network.gml", format="gml")
#combine for analysis
g.sn <- list(g.sn1, g.sn2, g.sn3)
g.sp <- list(g.sp1, g.sp2, g.sp3)
g.sm <- list(g.sm1, g.sm2, g.sm3)
g.cr <- list(g.cr1, g.cr2, g.cr3)
#get combined phyloseq object
ps <- readRDS("../results/combined-phylo-for-network-analysis.rds")
node_level_properties <- function(g, habitat){
cor_g <- g
#create a dataframe with 5 columns and a row for each node (ASV)
df<-as.data.frame(matrix(NA,ncol=5,nrow=length(degree(cor_g))))
#make ASV IDs row names of df
rownames(df)<-names(degree(cor_g))
#name the colums the node-level topological features
colnames(df)<-c("degree","betweenness","closeness","eigenvector","habitat")
#get betweenness
btw<-betweenness(cor_g)
#get closeness centrality
cls<-closeness(cor_g)
#get eigenvector centrality
egv<-evcent(cor_g)
#put the topological features into the dataframe
df[,1]<-degree(cor_g)
df[,2]<-btw
df[,3]<-cls
df[,4]<-egv$vector
df[,5]<-habitat
return(df)
}
sn.node = node_level_properties(g.sn[[1]], "Snow")
sp.node = node_level_properties(g.sp[[1]], "Spring Ice")
sm.node = node_level_properties(g.sm[[1]], "Summer Ice")
cr.node = node_level_properties(g.cr[[1]], "Cryoconite")
#combine and export node-level properties
write.csv(rbind(sn.node, sp.node, sm.node, cr.node), "../results/node-properties.csv")
ps = ps
node_df = sn.node
df <- node_df
#get taxa info of ASVs
taxonomy <- data.frame(tax_table(ps))
network_taxa <- subset(taxonomy, rownames(taxonomy) %in% rownames(df))
x = network_taxa %>%
mutate(Phylum = ifelse(is.na(Phylum), paste0(Domain, " P.",Phylum), Phylum)) %>%
mutate(Class = ifelse(is.na(Class), paste0(Phylum, " C.", Class), Class)) %>%
mutate(Order = ifelse(is.na(Order), paste0(Class, " O.", Order), Order)) %>%
mutate(Family = ifelse(is.na(Family), paste0(Order, " F.", Family), Family)) %>%
mutate(Genus = ifelse(is.na(Genus), paste0(Family, " G.", Genus), Genus)) %>%
mutate(Genus = ifelse(Genus == "uncultured", paste0(Family, " uncult."), Genus))
#replace anything that says NA with Genus Unknown
y = x
y$Phylum <- gsub("P.NA", "(Genus Unknown)", y$Phylum)
y$Class <- gsub("P.NA C.NA", "(Genus Unknown)", y$Class)
y$Class <- gsub("C.NA", "(Genus Unknown)", y$Class)
y$Order <- gsub("P.NA C.NA O.NA", "(Genus Unknown)", y$Order)
y$Order <- gsub("C.NA O.NA", "(Genus Unknown)", y$Order)
y$Order <- gsub("O.NA", "(Genus Unknown)", y$Order)
y$Family <- gsub("P.NA C.NA O.NA F.NA", "(Genus Unknown)", y$Family)
y$Family <- gsub("C.NA O.NA F.NA", "(Genus Unknown)", y$Family)
y$Family <- gsub("O.NA F.NA", "(Genus Unknown)", y$Family)
y$Family <- gsub("F.NA", "(Genus Unknown)", y$Family)
y$Genus <- gsub("P.NA C.NA O.NA F.NA G.NA", "(Genus Unknown)", y$Genus)
y$Genus <- gsub("C.NA O.NA F.NA G.NA", "(Genus Unknown)", y$Genus)
y$Genus <- gsub("O.NA F.NA G.NA", "(Genus Unknown)", y$Genus)
y$Genus <- gsub("F.NA G.NA", "(Genus Unknown)", y$Genus)
y$Genus <- gsub("G.NA", "(Genus Unknown)", y$Genus)
network_taxa = y
out.king <- network_taxa %>%
dplyr::group_by(Kingdom) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
out.dom <- network_taxa %>%
dplyr::group_by(Domain) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
#what percentage are micrometazoans
out.met = network_taxa[network_taxa$Phylum %in% c("Tardigrada", "Rotifera", "Nematozoa"),]
met.perc = round((nrow(out.met)/nrow(network_taxa))*100, 2)
out.phy <- network_taxa %>%
dplyr::group_by(Phylum) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
out.cla <- network_taxa %>%
dplyr::group_by(Class) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
out.ord <- network_taxa %>%
dplyr::group_by(Order) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
out.fam <- network_taxa %>%
dplyr::group_by(Family) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
out.gen <- network_taxa %>%
dplyr::group_by(Genus) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
network_tax <- function(ps, node_df){
df <- node_df
#get taxa info of ASVs
taxonomy <- data.frame(tax_table(ps))
network_taxa <- subset(taxonomy, rownames(taxonomy) %in% rownames(df))
x = network_taxa %>%
mutate(Phylum = ifelse(is.na(Phylum), paste0(Domain, " P.",Phylum), Phylum)) %>%
mutate(Class = ifelse(is.na(Class), paste0(Phylum, " C.", Class), Class)) %>%
mutate(Order = ifelse(is.na(Order), paste0(Class, " O.", Order), Order)) %>%
mutate(Family = ifelse(is.na(Family), paste0(Order, " F.", Family), Family)) %>%
mutate(Genus = ifelse(is.na(Genus), paste0(Family, " G.", Genus), Genus)) %>%
mutate(Genus = ifelse(Genus == "uncultured", paste0(Family, " uncult."), Genus))
#replace anything that says NA with Genus Unknown
y = x
y$Phylum <- gsub("P.NA", "(Genus Unknown)", y$Phylum)
y$Class <- gsub("P.NA C.NA", "(Genus Unknown)", y$Class)
y$Class <- gsub("C.NA", "(Genus Unknown)", y$Class)
y$Order <- gsub("P.NA C.NA O.NA", "(Genus Unknown)", y$Order)
y$Order <- gsub("C.NA O.NA", "(Genus Unknown)", y$Order)
y$Order <- gsub("O.NA", "(Genus Unknown)", y$Order)
y$Family <- gsub("P.NA C.NA O.NA F.NA", "(Genus Unknown)", y$Family)
y$Family <- gsub("C.NA O.NA F.NA", "(Genus Unknown)", y$Family)
y$Family <- gsub("O.NA F.NA", "(Genus Unknown)", y$Family)
y$Family <- gsub("F.NA", "(Genus Unknown)", y$Family)
y$Genus <- gsub("P.NA C.NA O.NA F.NA G.NA", "(Genus Unknown)", y$Genus)
y$Genus <- gsub("C.NA O.NA F.NA G.NA", "(Genus Unknown)", y$Genus)
y$Genus <- gsub("O.NA F.NA G.NA", "(Genus Unknown)", y$Genus)
y$Genus <- gsub("F.NA G.NA", "(Genus Unknown)", y$Genus)
y$Genus <- gsub("G.NA", "(Genus Unknown)", y$Genus)
network_taxa = y
out.dom <- network_taxa %>%
dplyr::group_by(Domain) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
#what percentage are micrometazoans
out.met = network_taxa[network_taxa$Phylum %in% c("Tardigrada", "Rotifera", "Nematozoa"),]
met.perc = round((nrow(out.met)/nrow(network_taxa))*100, 2)
out.phy <- network_taxa %>%
dplyr::group_by(Phylum) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
out.cla <- network_taxa %>%
dplyr::group_by(Class) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
out.ord <- network_taxa %>%
dplyr::group_by(Order) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
out.fam <- network_taxa %>%
dplyr::group_by(Family) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
out.gen <- network_taxa %>%
dplyr::group_by(Genus) %>%
dplyr::summarise(n= n()) %>%
mutate(perc=n/sum(n)*100)
return(res.list = list(network_taxa, out.dom, out.phy, out.cla, out.ord, out.fam, out.gen, met.perc, out.met$Genus))
}
#Snow Domain
sn.net.tax = network_tax(ps, sn.node)
#Snow Domain
sn.net.tax = network_tax(ps, sn.node)
sn.df.dom1 = sn.net.tax[[2]]
sn.df.dom2 <- sn.df.dom1[order(sn.df.dom1$perc, decreasing = TRUE), ]
row.names(sn.df.dom2) <- NULL
View(sn.df.dom2)
sn.df.dom2$Habitat = "Snow"
#Spring ice Domain
sp.net.tax = network_tax(ps, sp.node)
sp.df.dom1 = sp.net.tax[[2]]
sp.df.dom2 <- sp.df.dom1[order(sp.df.dom1$perc, decreasing = TRUE), ]
sp.df.dom2$Habitat = "Spring Ice"
#Summer ice Domain
sm.net.tax = network_tax(ps, sm.node)
sm.df.dom1 = sm.net.tax[[2]]
sm.df.dom2 <- sm.df.dom1[order(sm.df.dom1$perc, decreasing = TRUE), ]
sm.df.dom2$Habitat = "Summer Ice"
#DOMAIN BREAKDOWN
#Snow Domain
sn.net.tax = network_tax(ps, sn.node)
sn.df.dom1 = sn.net.tax[[2]]
sn.df.dom2 <- sn.df.dom1[order(sn.df.dom1$perc, decreasing = TRUE), ]
sn.df.dom2$Habitat = "Snow"
#Spring ice Domain
sp.net.tax = network_tax(ps, sp.node)
sp.df.dom1 = sp.net.tax[[2]]
sp.df.dom2 <- sp.df.dom1[order(sp.df.dom1$perc, decreasing = TRUE), ]
sp.df.dom2$Habitat = "Spring Ice"
#Summer ice Domain
sm.net.tax = network_tax(ps, sm.node)
sm.df.dom1 = sm.net.tax[[2]]
sm.df.dom2 <- sm.df.dom1[order(sm.df.dom1$perc, decreasing = TRUE), ]
sm.df.dom2$Habitat = "Summer Ice"
#cryoconite Domain
cr.net.tax = network_tax(ps, cr.node)
cr.df.dom1 = cr.net.tax[[2]]
cr.df.dom2 <- cr.df.dom1[order(cr.df.dom1$perc, decreasing = TRUE), ]
cr.df.dom2$Habitat = "Cryoconite"
#combine and export
write.csv(rbind(sn.df.dom2, sp.df.dom2, sm.df.dom2, cr.df.dom2), "../results/network-domains.csv")
#combine and export
x = rbind(sn.df.dom2, sp.df.dom2, sm.df.dom2, cr.df.dom2)
x$perc = round(x$perc,2)
write.csv(x, "../results/network-domains.csv")
View(x)
