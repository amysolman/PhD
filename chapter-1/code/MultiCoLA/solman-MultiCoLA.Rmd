---
title: "MultiCoLA"
author: "Amy Solman"
date: "19/02/2022"
output: html_document
---
SCRIPTS AND GUIDE DOWNLOADED FROM: https://www.mpi-bremen.de/en/Softwares.html#section1550

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Multivariate Cutoff Level Analysis (MultiCoLA)
This script will carry out the analysis described by Gobet et al., 2010 to assess the impact of rarity and abundance cut offs on dataset structure. This will then inform the cut offs set for further analysis.

Questions this script will answer:
1) What percentage of the least abundant sequences can be removed whilst maintaining ecological patterns.

Process:
A) Successively remove rare types (the least abundant ASVs). E.g. remove the 5% least abundant ASVs, 10% least abundant, 15% least abundant...
B) For each successive truncation of the dataset, measure the variation in dataset structure.
C) For each successive truncation of the dataset, measure the extracted variation (this is to do with eigenvalues) between the original and truncated data sets. 
D) If environmental data is available, compare the ecological interpretation between the original and truncated data sets.

Two types of abundance cut off levels
Data set-based: Truncated datasets produced by removing chosen proportion (5%, 10% etc) of are ASVs from total sum of sequences in the data set.
Sample-based: Select 15 cut offs from 1 to the lowest number of maximum ASVs occurences per sample (in the case of our 16S data here the lower number of maximum occurences in 375).

Clear workspace and import data
```{r}
rm(list=ls())
graphics.off()

#load packages
# install.packages("janitor")
# library(janitor) #to get column totals
# library(tibble) #to convert rowname to column and vice versa
library(vegan)
library(MASS)

#load phyloseq object
ps_pro <- readRDS("../../results/16S/phylo-objects/16S-phyloseq-object-rarefied-decontam.rds") 
#ps_euk <- readRDS("../results/18S/phylo-objects/18S-phyloseq-object-rarefied.rds") 

#source our data prep function
source("solman-MultiCoLA-input-file-prep.R")

#source pre-written MultiCoLA functions from Gobet et al
source("taxa.pooler.1.4.r")
source("COtables.1.4.r")
source("cutoff.impact.1.4.r")
```

*Sort original data set according to decreasing number of sequences per ASV
```{r}
# asv_tab <- data.frame(otu_table(ps_pro))
# asv_abun <- data.frame(rowSums(asv_tab))
# order_abun <- data.frame(asv_abun[order(-asv_abun$rowSums.asv_tab.), , drop=FALSE])

# asv_tab <- data.frame(t(otu_table(ps_pro)))
# asv_tab <- tibble::rownames_to_column(asv_tab, "SAMPLE")
# asv_tab <- asv_tab %>%
#   adorn_totals("row")
# asv_tab <- tibble::column_to_rownames(asv_tab, "SAMPLE")
# 
# x <- asv_tab[,order(-asv_tab[76,])]
# # asv_tot <- data.frame(colSums(asv_tab))
# order_abun <- data.frame(asv_tab[, order(-asv_tab[,nrow(asv_tab)]), , drop=FALSE])
```

What is the lowest maximum ASVs sequences seen in each sample?
```{r}
#Find the mimimum value of the maximum values for each row (sample)
# df_max_min <- min(do.call(pmax, asv_tab[1:nrow(asv_tab)-1,]))
```

Select 15 cut off levels
```{r}
# sample_based_cut_offs = round(seq(from = 1, to = df_max_min, length.out = 15))
```

Load and prepare data
```{r}
my_phylo = ps_pro
taxa_levels = 6
M <- MultiCoLA_input_file_prep(my_phylo)
```

Obtain a matrix for each taxonomic level
```{r}
all_taxa_pooled<-taxa.pooler(M)
```

Generate truncated data sets based on dominant/rare and data set/sample: Application of successive cutoffs on each original matrix
```{r}
#Dataset based dominant 
ADS_DOM_store <- list()
for (i in 1:taxa_levels){
  ADS_DOM_store[[i]] <-COtables(all_taxa_pooled[[i]], Type="ADS",typem="dominant")
}

#Dataset based rare
ADS_RARE_store <- list()
for (i in 1:taxa_levels){
  ADS_RARE_store[[i]] <-COtables(all_taxa_pooled[[i]], Type="ADS",typem="rare")
}

#Sample based dominant
SAM_DOM_store <- list()
for (i in 1:taxa_levels){
  SAM_DOM_store[[i]] <-COtables(all_taxa_pooled[[i]], Type="SAM",typem="dominant")
}

#Sample based rare
SAM_RARE_store <- list()
for (i in 1:taxa_levels){
  SAM_RARE_store[[i]] <-COtables(all_taxa_pooled[[i]], Type="SAM",typem="rare")
}

```

Calculation of Spearman (or Pearson, Kendall) correlations and Procrustes correlations between the original dataset and the truncated ones
```{r}
corr.all<-cutoff.impact(all_taxa_pooled,Type="ADS",corcoef="spearman",typem="dominant")

```