---
title: "16S-09-CCA"
author: "Amy Solman"
date: "29/11/2021"
output: html_document
---

Great tutorial: https://fromthebottomoftheheap.net/slides/advanced-vegan-webinar-2020/advanced-vegan#1
http://www.hiercourse.com/docs/Rnotes_multivariate.pdf
https://fukamilab.github.io/BIO202/06-B-constrained-ordination.html

Canonical Correspondence Analysis
A form of constrained ordination = associating two or more quantitative data sets (where simple/unconstrained ordination analyses a single data matrix).
CCA is the CONSTRAINED form of correspondence analysis (CA). CA = unconstrained ordination that associates one quantiative data set and a categorial dataset (e.g. count data from different sample locations).
Redundancy analysis (RDA) is the CONSTRAINED form of principal component analysis (PCA).


Clear workspace and load packages
```{r}
rm(list=ls())
graphics.off()

library(vegan) #for diversity indices
library(dplyr) #for coalesce function
library(stringr)
#install.packages("corrplot")
library(corrplot)
```

Load Data
```{r}
#TOTAL DATASET
ps <- readRDS("../../results/16S/phylo-objects/16S-phyloseq-object-rarefied-decontam.rds")

#Total Abundant
ps.abun <- readRDS("../../results/16S/phylo-objects/16S-total-abundant.rds")
#Total Intermediate
ps.int <- readRDS("../../results/16S/phylo-objects/16S-total-intermediate.rds")
#Total Rare
ps.rare <- readRDS("../../results/16S/phylo-objects/16S-total-rare.rds")
```

Function for getting agglomerated asv data
```{r}
agg_my_counts <- function(phylo, level){
  
  spe <- data.frame(t(otu_table(phylo)))

  #get out taxonomy table
  tax_tab <- data.frame(tax_table(phylo))
  #replace NAs with Unknown
  tax_tab[is.na(tax_tab)] <- "Unknown"
  colnames(spe) <- tax_tab[, level]

  #aggregate count data
  x <- t(spe)
  new_df=aggregate(x, by=list(rownames(x)),sum)
  new_counts <- t(new_df)
  colnames(new_counts) <- new_counts[1,]
  new_counts <- new_counts[-1,]
  df <- data.frame(new_counts)
  #make dataframe numeric
  df[] <- lapply(df, as.numeric)
  df <- df[,! names(df) %in% c("Unknown")]
  
  
  return(df)
}

# #Test function
# phylo = ps
# rank = "Class"
```

Function for getting environmental data
```{r}

get_my_meta <- function(phylo, perc){
  
#Get metadata of samples
samp_data <- data.frame(sample_data(phylo))

#list of variables we're interested in 
keeps <- c("Distance_To_Sea", "Elevation", "Water_Depth", "Sediment_Depth", "Total_Depth","Conductivity", "pH", "DOC_mgL.1",
           "Cl_merge", "SO4_merge", "Na_merge", "K_merge", "Mg_merge","Ca_merge", "HCO3_merge", "Radius", "EW", "NS")
samp_data <- samp_data[ , (names(samp_data) %in% keeps)]

#get cryoconite hole areas
area1 <- pi*samp_data$Radius^2
area2 <- pi*(samp_data$NS/2)*(samp_data$EW/2)
samp_data$Area <- coalesce(area1,area2)

drops <- c("EW", "NS", "Radius")
samp_data <- samp_data[ , !(names(samp_data) %in% drops)]

#make sure data are numeric
samp_data[1:16] <- data.frame(lapply(samp_data[1:16],as.numeric))

#change sample names 
names(samp_data) <- c("Distance_To_Sea", "Elevation", "Water_Depth", "Sediment_Depth", "Total_Depth","Conductivity", "pH", "DOC_mgL.1", "Cl", "SO4", "Na", "K", "Mg","Ca", "HCO3", "Area")

  #remove columns with more than 50% missing variables
  samp_data_trim <- samp_data[ lapply( samp_data, function(x) sum(is.na(x)) / length(x) ) < perc ]
  
  #Only keep complete cases
  samp_data_trim_complete <- samp_data_trim[complete.cases(samp_data_trim),]
  
return(samp_data_trim_complete)
}

#Test function
# phylo = ps
# perc = 0.5
```

Function for getting spatial data
```{r}
get_my_long_lat <- function(phylo){
  
#get metadata
meta <- data.frame(sample_data(phylo))

#put a negative sign in front of all the south latitude coords
for (i in 1:nrow(meta)){
  if (meta$Pole[i] == "Antarctic"){
    meta$Glacier_Latitude[i] <- c(paste0("-", meta$Glacier_Latitude[i]))
    meta$Cryoconite_Latitude[i] <- c(paste0("-", meta$Cryoconite_Latitude[i]))
  }
}

#Some of our cryoconite holes don't have specific coords so we'll use the glacier coordinates
#remove letters from glacier coord strings
meta$Glacier_Latitude <- as.numeric(str_sub(meta$Glacier_Latitude,1,nchar(meta$Glacier_Latitude)-1))
meta$Glacier_Longitude <- as.numeric(str_sub(meta$Glacier_Longitude,1,nchar(meta$Glacier_Longitude)-1))

glac_lat <- meta$Glacier_Latitude
glac_long <- meta$Glacier_Longitude

#get latitude of each sample
cryo_lat <- as.numeric(meta$Cryoconite_Latitude)
#get longitude of each sample
cryo_long <- as.numeric(meta$Cryoconite_Longitude)

#replace any missing cryoconite coords with those of it's glacier
for (j in 1:length(cryo_lat)){
  if (is.na(cryo_lat[j])){
    cryo_lat[j] <- glac_lat[j]
    cryo_long[j] <- glac_long[j]
  }
}

#put into matrix
long.lat <- as.data.frame(cbind(cryo_long, cryo_lat))
rownames(long.lat) = rownames(meta)

return(long.lat)

}

# #Test function
# phylo = ps
# res <- get_my_long_lat(ps)
```

CCA:Full
```{r}
#Function testing area
phylo = ps
perc = 0.5
level = "Class"
collin = 30
abundance_class <- "total"
#do_my_cca_full(ps, 0.5, "Class", 30, "total")

do_my_cca_full <- function(phylo, perc, level, collin, abundance_class){
  
  #get community data
  varespec <- agg_my_counts(phylo, level)
  
  #get my metadata 
  varechem <- get_my_meta(phylo, perc)
  #trim species to match remaining metadata
  varespec_trim <- varespec[(rownames(varespec) %in% rownames(varechem)),]
  
  #perform initial CCA
  #CCA
  cca1 <- cca(varespec_trim ~., data=varechem)
  cca1
  
  #permutation test on model
  pstat <- permustats(anova(cca1))
  summary(pstat) #how important is the fitted model compared to null model
  
  #plot results of the permutation test
  pdf(paste0("../../results/16S/graphs/CCA/16S-", abundance_class, "-first-CCA-permutation-test-plot.pdf"))
  densityplot(pstat, main=paste0("16S ", abundance_class, " Community First CCA Permutation Test"))
  dev.off()
  
  #check significant of first model
  signif1 <- anova.cca(cca1)
  
  #plot model
  pdf(paste0("../../results/16S/graphs/CCA/16S-", abundance_class, "-first-full-CCA-plot.pdf"))
  plot(cca1, xlim=c(-1.5,2), ylim=c(-1,1.5), display=c("sp","cn","wa"))
  text(-1, 1, paste0("p= ", as.numeric(signif1$`Pr(>F)`)[1]))
  text(-1, 0.7, paste0("F= ", as.numeric(round(signif1$F[1], digits=4))))
  title(main=paste0("16S ", abundance_class, " Community First Full CCA"))
  dev.off()

  
  #plot correlation matrix of independent variables
  #let's explore multicollinearity with a correlation matrix
  res <- cor(varechem)
  
  #plot the correlations
  pdf(paste0("../../results/16S/graphs/16S-metadata-correlation-matrix.pdf"))
  cor_plot <- corrplot(res, type = "upper", order = "hclust", 
           tl.col = "black", tl.srt = 45)
  dev.off()
  
  #Get variance inflation factors of independent variables
  vif_res <- data.frame(vif.cca(cca1))
  
  #Remove variable with too much collinearity
  var_to_keep <- vector()
  for (i in 1:nrow(vif_res)){
    if (vif_res[i,] < collin){
      var_to_keep <- c(var_to_keep, rownames(vif_res)[i])
    }
  }
  varechem_reduce <- varechem[,names(varechem) %in% var_to_keep]
  
  #Now we'll do stepwise selection to find the remaining variables that best explain our data
  upr <- cca(varespec_trim ~ ., data = varechem_reduce) #model with all our variables
  lwr <- cca(varespec_trim ~ 1, data = varechem_reduce) #null model
  set.seed(1)
  #Stepwise selection via adjusted R
  mod <- ordiR2step(lwr, upr, trace = FALSE)
  mod 
  
  #check significant of final model
  signif2 <- anova.cca(mod)
  
  #plot model
  pdf(paste0("../../results/16S/graphs/CCA/16S-", abundance_class, "-final-full-CCA-plot.pdf"))
  plot(mod, xlim=c(-1.5,2), ylim=c(-1,1.5), display=c("sp","cn","wa"))
  text(-1, 1, paste0("p= ", as.numeric(signif2$`Pr(>F)`)[1]))
  text(-1, 0.7, paste0("F= ", as.numeric(round(signif2$F[1], digits=4))))
  title(main=paste0("16S ", abundance_class, " Community Final Full CCA"))
  dev.off()
}

```

Carry out CCAs
```{r}
do_my_cca_full(ps, 0.5, "Class", 30, "total")
do_my_cca_full(ps.rare, 0.5, "Class", 30, "rare")
do_my_cca_full(ps.abun, 0.5, "Class", 30, "abundant")
do_my_cca_full(ps.int, 0.5, "Class", 30, "intermediate")
```


<!-- CCA:Partial Come back to this -->
<!-- ```{r} -->
<!-- #Function testing area -->
<!-- phylo = ps -->
<!-- perc = 0.5 -->
<!-- level = "Class" -->
<!-- collin = 30 -->
<!-- abundance_class <- "total" -->
<!-- do_my_cca_partial(ps, 0.5, "Class", 30, "total") -->

<!-- do_my_cca_partial <- function(phylo, perc, level, collin, abundance_class){ -->

<!--   #get community data -->
<!--   varespec <- agg_my_counts(phylo, "Class") -->

<!--   #get spatial data -->
<!--   spatial = get_my_long_lat(phylo) -->

<!--   #get my metadata  -->
<!--   varechem <- get_my_meta(phylo, perc) -->
<!--   #trim species to match remaining metadata -->
<!--   varespec_trim <- varespec[(rownames(varespec) %in% rownames(varechem)),] -->
<!--   spatial_trim <- spatial[(rownames(spatial) %in% rownames(varechem)),] -->

<!--   #add lat and long coords to metadata -->
<!--   varechem_comb <- cbind(varechem, spatial_trim) -->

<!--   #Initial CCA -->
<!--   pcca1 <- cca(varespec_trim ~. + Condition(cryo_lat + cryo_long), data=varechem_comb)  -->

<!--   #check significant of first model -->
<!--   signif1 <- anova.cca(pcca1) -->

<!--   #plot model -->
<!--   pdf(paste0("../../results/16S/graphs/CCA/16S-", abundance_class, "-first-partial-CCA-plot.pdf")) -->
<!--   plot(pcca1, xlim=c(-1.5,2), ylim=c(-1,1.5), display=c("sp","cn","wa")) -->
<!--   text(-1, 1, paste0("p= ", as.numeric(signif1$`Pr(>F)`)[1])) -->
<!--   text(-1, 0.7, paste0("F= ", as.numeric(round(signif1$F[1], digits=4)))) -->
<!--   title(main=paste0("16S ", abundance_class, " Community First Partial CCA")) -->
<!--   dev.off() -->

<!--   #plot correlation matrix of independent variables -->
<!--   #let's explore multicollinearity with a correlation matrix -->
<!--   res <- cor(varechem) -->

<!--   #plot the correlations -->
<!--   pdf(paste0("../../results/16S/graphs/CCA/16S-", abundance_class, "-metadata-correlation-matrix.pdf")) -->
<!--   cor_plot <- corrplot(res, type = "upper", order = "hclust",  -->
<!--            tl.col = "black", tl.srt = 45) -->
<!--   dev.off() -->

<!--   #Get variance inflation factors of independent variables -->
<!--   vif_res <- data.frame(vif.cca(pcca1), row.names = ) -->

<!--   #Remove variable with too much collinearity -->
<!--   var_to_keep <- vector() -->
<!--   for (i in 1:nrow(vif_res)){ -->
<!--     if (vif_res[i,] < collin && !is.na(vif_res[i,])){ -->
<!--       var_to_keep <- c(var_to_keep, rownames(vif_res)[i]) -->
<!--     } -->
<!--   } -->
<!--   varechem_reduce <- varechem[,names(varechem) %in% var_to_keep] -->

<!--   #Now we'll do stepwise selection to find the remaining variables that best explain our data -->
<!--   upr <- cca(varespec_trim ~. + Condition(cryo_lat + cryo_long), data=varechem_reduce)  -->
<!--   #upr <- cca(varespec_trim ~ ., data = varechem_reduce) #model with all our variables -->
<!--   lwr <- cca(varespec_trim ~ 1 + Condition(cryo_lat + cryo_long), data=varechem_reduce)  -->
<!--   #lwr <- cca(varespec_trim ~ 1, data = varechem_reduce) #null model -->
<!--   set.seed(1) -->
<!--   #Stepwise selection via adjusted R -->
<!--   mod <- ordiR2step(lwr, upr, trace = FALSE) -->
<!--   mod  -->

<!--   #check significant of final model -->
<!--   signif2 <- anova.cca(mod) -->

<!--   #plot model -->
<!--   pdf(paste0("../../results/16S/graphs/CCA/16S-", abundance_class, "-final-partial-CCA-plot.pdf")) -->
<!--   plot(mod, xlim=c(-1.5,2), ylim=c(-1,1.5), display=c("sp","cn","wa")) -->
<!--   text(-1, 1, paste0("p= ", as.numeric(signif2$`Pr(>F)`)[1])) -->
<!--   text(-1, 0.7, paste0("F= ", as.numeric(round(signif2$F[1], digits=4)))) -->
<!--   title(main=paste0("16S ", abundance_class, " Community Final Partial CCA")) -->
<!--   dev.off() -->
<!-- } -->

<!-- ``` -->




