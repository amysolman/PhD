---
title: "Variation Partitioning Analysis"
author: "Amy Solman"
date: "08/12/2021"
output: html_document
---

Variation Partitioning Analysis
1) Redundancy analysis to find significant environmental factors
2) Redundancy analysis to find significant spatial factors
3) Partition variation among the remaining environmental and spatial factors
4) Test significance and plot
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Clear workspace and load packages
```{r}
rm(list=ls())
graphics.off()

library(vegan) #for diversity indices
library(dplyr) #for coalesce function
library(stringr)
#install.packages("corrplot")
library(corrplot)
#install.packages("insight")
library(insight)
```

Load Data
```{r}
#TOTAL DATASET
ps <- readRDS("../../results/16S/phylo-objects/16S-phyloseq-object-rarefied-decontam.rds")

#Total Abundant
ps.abun <- readRDS("../../results/16S/phylo-objects/16S-total-abundant.rds")
#Total Intermediate
ps.int <- readRDS("../../results/16S/phylo-objects/16S-total-intermediate.rds")
#Total Rare
ps.rare <- readRDS("../../results/16S/phylo-objects/16S-total-rare.rds")
```

Function for getting agglomerated asv data
```{r}
agg_my_counts <- function(phylo, level){
  
  spe <- data.frame(t(otu_table(phylo)))

  #get out taxonomy table
  tax_tab <- data.frame(tax_table(phylo))
  #replace NAs with Unknown
  tax_tab[is.na(tax_tab)] <- "Unknown"
  colnames(spe) <- tax_tab[, level]

  #aggregate count data
  x <- t(spe)
  new_df=aggregate(x, by=list(rownames(x)),sum)
  new_counts <- t(new_df)
  colnames(new_counts) <- new_counts[1,]
  new_counts <- new_counts[-1,]
  df <- data.frame(new_counts)
  #make dataframe numeric
  df[] <- lapply(df, as.numeric)
  df <- df[,! names(df) %in% c("Unknown")]
  
  
  return(df)
}

# #Test function
# phylo = ps
# rank = "Class"
```

Function for getting environmental data
```{r}

get_my_meta <- function(phylo, perc){
  
#Get metadata of samples
samp_data <- data.frame(sample_data(phylo))

#list of variables we're interested in 
keeps <- c("Distance_To_Sea", "Elevation", "Water_Depth", "Sediment_Depth", "Total_Depth","Conductivity", "pH", "DOC_mgL.1",
           "Cl_merge", "SO4_merge", "Na_merge", "K_merge", "Mg_merge","Ca_merge", "HCO3_merge", "Radius", "EW", "NS")
samp_data <- samp_data[ , (names(samp_data) %in% keeps)]

#get cryoconite hole areas
area1 <- pi*samp_data$Radius^2
area2 <- pi*(samp_data$NS/2)*(samp_data$EW/2)
samp_data$Area <- coalesce(area1,area2)

drops <- c("EW", "NS", "Radius")
samp_data <- samp_data[ , !(names(samp_data) %in% drops)]

#make sure data are numeric
samp_data[1:16] <- data.frame(lapply(samp_data[1:16],as.numeric))

#change sample names 
names(samp_data) <- c("Distance_To_Sea", "Elevation", "Water_Depth", "Sediment_Depth", "Total_Depth","Conductivity", "pH", "DOC_mgL.1", "Cl", "SO4", "Na", "K", "Mg","Ca", "HCO3", "Area")

  #remove columns with more than 50% missing variables
  samp_data_trim <- samp_data[ lapply( samp_data, function(x) sum(is.na(x)) / length(x) ) < perc ]
  
  #Only keep complete cases
  samp_data_trim_complete <- samp_data_trim[complete.cases(samp_data_trim),]
  
return(samp_data_trim_complete)
}

#Test function
# phylo = ps
# perc = 0.5
```

Function for getting spatial data
```{r}
get_my_long_lat <- function(phylo){
  
#get metadata
meta <- data.frame(sample_data(phylo))

#put a negative sign in front of all the south latitude coords
for (i in 1:nrow(meta)){
  if (meta$Pole[i] == "Antarctic"){
    meta$Glacier_Latitude[i] <- c(paste0("-", meta$Glacier_Latitude[i]))
    meta$Cryoconite_Latitude[i] <- c(paste0("-", meta$Cryoconite_Latitude[i]))
  }
}

#Some of our cryoconite holes don't have specific coords so we'll use the glacier coordinates
#remove letters from glacier coord strings
meta$Glacier_Latitude <- as.numeric(str_sub(meta$Glacier_Latitude,1,nchar(meta$Glacier_Latitude)-1))
meta$Glacier_Longitude <- as.numeric(str_sub(meta$Glacier_Longitude,1,nchar(meta$Glacier_Longitude)-1))

glac_lat <- meta$Glacier_Latitude
glac_long <- meta$Glacier_Longitude

#get latitude of each sample
cryo_lat <- as.numeric(meta$Cryoconite_Latitude)
#get longitude of each sample
cryo_long <- as.numeric(meta$Cryoconite_Longitude)

#replace any missing cryoconite coords with those of it's glacier
for (j in 1:length(cryo_lat)){
  if (is.na(cryo_lat[j])){
    cryo_lat[j] <- glac_lat[j]
    cryo_long[j] <- glac_long[j]
  }
}

#put into matrix
long.lat <- as.data.frame(cbind(cryo_long, cryo_lat))
rownames(long.lat) = rownames(meta)

return(long.lat)

}

# #Test function
# phylo = ps
# res <- get_my_long_lat(ps)
```

Function for generating dbMEMs and scores
```{r}
get_my_dbMDM_scores <- function(phylo){
  
  coords <- get_my_long_lat(phylo)
  
  #represent spatial patterns through PCNMs (dbMEM)
  cryo_pcnm <- pcnm(dist(coords))
  
  #get scores for dbMEM
  cryo_dbMEM <- as.data.frame(scores(cryo_pcnm))
  
  return(cryo_dbMEM)
}

```

Select environmental factors
```{r}
#Function testing area
# phylo = ps
# perc = 0.5
# level = "Class"
# collin = 10

best_environmental <- function(phylo, perc, level, collin){
  
  #get community data
  varespec <- agg_my_counts(phylo, level)
  
  #transform count data
  varespech <- decostand(varespec, method = "hellinger")
  
  #get my metadata 
  varechem <- get_my_meta(phylo, perc)
  #trim species to match remaining metadata
  varespech_trim <- varespech[(rownames(varespech) %in% rownames(varechem)),]
  
  #perform initial RDA
  rda1 <- rda(varespech_trim ~., data=varechem)
  rda1
  
  #Get variance inflation factors of independent variables
  vif_res <- data.frame(vif.cca(rda1))
  
  #Remove variable with too much collinearity
  var_to_keep <- vector()
  for (i in 1:nrow(vif_res)){
    if (vif_res[i,] < collin){
      var_to_keep <- c(var_to_keep, rownames(vif_res)[i])
    }
  }
  varechem_reduce <- varechem[,names(varechem) %in% var_to_keep]
  
  #Now we'll do stepwise selection to find the remaining variables that best explain our data
  upr <- rda(varespech_trim ~ ., data = varechem_reduce) #model with all our variables
  lwr <- rda(varespech_trim ~ 1, data = varechem_reduce) #null model
  set.seed(1)
  #Stepwise selection via adjusted R
  mod <- ordistep(lwr, upr, trace = FALSE)
  mod 
  
  #return the significant environmental factors
  x <- as.data.frame(find_predictors(mod))
  return(x)
  
}
```

Select spatial factors
```{r}
#Function testing area
# phylo <- ps
# level <- "Class"

best_spatial <- function(phylo, level){
  
  #get community data
  varespec <- agg_my_counts(phylo, level)
  
  #transform count data
  varespech <- decostand(varespec, method = "hellinger")
  
  #get coords from phyloseq object
  spatial <- get_my_long_lat(phylo)
  #calculate dbMEMs
  dbMEMs <- as.data.frame(scores(pcnm(dist(spatial))))
  
  #perform initial RDA
  rda1 <- rda(varespech ~., data=dbMEMs)
  rda1
  
  #check significant of first model
  signif1 <- anova.cca(rda1)
  
  #plot model
  plot(rda1, xlim=c(-1.5,2), ylim=c(-1,1.5), display=c("sp","cn","wa"))
  text(-1, 1, paste0("p= ", as.numeric(signif1$`Pr(>F)`)[1]))
  text(-1, 0.7, paste0("F= ", as.numeric(round(signif1$F[1], digits=4))))
  title(main=paste0("16S ", abundance_class, " Community First Spatial Full RDA"))

  
  #Now we'll do stepwise selection to find the remaining variables that best explain our data
  upr <- rda(varespech ~ ., data = dbMEMs) #model with all our variables
  lwr <- rda(varespech ~ 1, data = dbMEMs) #null model
  set.seed(1)
  #Stepwise selection via adjusted R
  mod <- ordistep(lwr, upr, trace = FALSE)
  mod 
  
  #check significant of final model
  signif2 <- anova.cca(mod)
  
  #plot model
  plot(mod, xlim=c(-1.5,2), ylim=c(-1,1.5), display=c("sp","cn","wa"))
  text(-1, 1, paste0("p= ", as.numeric(signif2$`Pr(>F)`)[1]))
  text(-1, 0.7, paste0("F= ", as.numeric(round(signif2$F[1], digits=4))))
  title(main=paste0("16S ", abundance_class, " Community Final Spatial Full RDA"))
  
  #return the significant spatial factors
  x <- as.data.frame(find_predictors(mod))
  return(x)
  
}

```

Function for basic VPA
```{r}

#Data for testing
# data(mite)
# data(mite.env)
# data(mite.xy)
# 
# spe <- mite
# env <- mite.env
# spatial <- mite.xy

get_my_vpa <- function(spe, env, spatial){

  #How much do each of our predictor matrices explain variation in community composition?
  var <- varpart(spe, ~ ., spatial, data=env)
  
  #plot
  p <- plot(var, bg=1:2, Xnames=c("environmental", "spatial"), id.size=0.75)
  
  return(p)
}

```

Function for VPA with selected factors
```{r}
#Function testing area
# phylo = ps
# perc = 0.5
# level = "Class"
# collin = 30
# abundance_class <- "total"
# #Mock dataframes for testing 
# env_data <- data.frame(conditional=c("pH", "Ca"))

vpa_with_selected <- function(phylo, perc, level, collin, abundance_class){
  
  #get community data
  varespec <- agg_my_counts(phylo, level)
  #transform count data
  varespech <- decostand(varespec, method = "hellinger")
  
  #get my metadata 
  varechem <- get_my_meta(phylo, perc)
  #trim species to match remaining metadata
  varespech_trim <- varespech[(rownames(varespech) %in% rownames(varechem)),]
  
  #get coords from phyloseq object
  coords <- get_my_long_lat(phylo)
  #calculate dbMEMs
  dbMEMs <- as.data.frame(scores(pcnm(dist(coords))))
  #trim dbMEMs to match remaining metadata
  dbMEMs_trim <- dbMEMs[(rownames(dbMEMs) %in% rownames(varechem)),]
  
  #reduce our environmental and spatial factors to those we know are significant
  env <- best_environmental(phylo, perc, level, collin)
  best_spatial_res <- best_spatial(phylo, level)
  
  #trim env and spatial to significant factors
  env <- varechem[,(names(varechem) %in% best_env_res$conditional)]
  spatial <- as.data.frame(dbMEMs_trim[,(names(dbMEMs_trim) %in% best_spatial_res$conditional)])
  
  #How much do each of our predictor matrices explain variation in community composition?
  var <- varpart(varespech_trim, ~ ., spatial, data=env)
  
  #plot
  plot(var, bg=1:2, Xnames=c("environmental", "spatial"), id.size=0.75)
}

```
