---
title: "Redundancy Analysis"
author: "Amy Solman"
date: "09/10/2021"
output: html_document
---

http://dmcglinn.github.io/quant_methods/lessons/multivariate_models.html
https://fukamilab.github.io/BIO202/06-B-constrained-ordination.html 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Clear workspace and load packages
```{r}
rm(list=ls())
graphics.off()

library(vegan) #for diversity indices
library(dplyr) #for coalesce function
library(stringr)
#install.packages("corrplot")
library(corrplot)
```

Load Data
```{r}
#TOTAL DATASET
ps <- readRDS("../../results/16S/phylo-objects/16S-phyloseq-object-rarefied-decontam.rds")

#Total Abundant
ps.abun <- readRDS("../../results/16S/phylo-objects/16S-total-abundant.rds")
#Total Intermediate
ps.int <- readRDS("../../results/16S/phylo-objects/16S-total-intermediate.rds")
#Total Rare
ps.rare <- readRDS("../../results/16S/phylo-objects/16S-total-rare.rds")
```

Function for getting agglomerated asv data
```{r}
agg_my_counts <- function(phylo, level){
  
  spe <- data.frame(t(otu_table(phylo)))

  #get out taxonomy table
  tax_tab <- data.frame(tax_table(phylo))
  #replace NAs with Unknown
  tax_tab[is.na(tax_tab)] <- "Unknown"
  colnames(spe) <- tax_tab[, level]

  #aggregate count data
  x <- t(spe)
  new_df=aggregate(x, by=list(rownames(x)),sum)
  new_counts <- t(new_df)
  colnames(new_counts) <- new_counts[1,]
  new_counts <- new_counts[-1,]
  df <- data.frame(new_counts)
  #make dataframe numeric
  df[] <- lapply(df, as.numeric)
  df <- df[,! names(df) %in% c("Unknown")]
  
  
  return(df)
}

# #Test function
# phylo = ps
# rank = "Class"
```

Function for getting environmental data
```{r}

get_my_meta <- function(phylo, perc){
  
#Get metadata of samples
samp_data <- data.frame(sample_data(phylo))

#list of variables we're interested in 
keeps <- c("Distance_To_Sea", "Elevation", "Water_Depth", "Sediment_Depth", "Total_Depth","Conductivity", "pH", "DOC_mgL.1",
           "Cl_merge", "SO4_merge", "Na_merge", "K_merge", "Mg_merge","Ca_merge", "HCO3_merge", "Radius", "EW", "NS")
samp_data <- samp_data[ , (names(samp_data) %in% keeps)]

#get cryoconite hole areas
area1 <- pi*samp_data$Radius^2
area2 <- pi*(samp_data$NS/2)*(samp_data$EW/2)
samp_data$Area <- coalesce(area1,area2)

drops <- c("EW", "NS", "Radius")
samp_data <- samp_data[ , !(names(samp_data) %in% drops)]

#make sure data are numeric
samp_data[1:16] <- data.frame(lapply(samp_data[1:16],as.numeric))

#change sample names 
names(samp_data) <- c("Distance_To_Sea", "Elevation", "Water_Depth", "Sediment_Depth", "Total_Depth","Conductivity", "pH", "DOC_mgL.1", "Cl", "SO4", "Na", "K", "Mg","Ca", "HCO3", "Area")

  #remove columns with more than 50% missing variables
  samp_data_trim <- samp_data[ lapply( samp_data, function(x) sum(is.na(x)) / length(x) ) < perc ]
  
  #Only keep complete cases
  samp_data_trim_complete <- samp_data_trim[complete.cases(samp_data_trim),]
  
return(samp_data_trim_complete)
}

#Test function
# phylo = ps
# perc = 0.5
```

Function for getting spatial data
```{r}
get_my_long_lat <- function(phylo){
  
#get metadata
meta <- data.frame(sample_data(phylo))

#put a negative sign in front of all the south latitude coords
for (i in 1:nrow(meta)){
  if (meta$Pole[i] == "Antarctic"){
    meta$Glacier_Latitude[i] <- c(paste0("-", meta$Glacier_Latitude[i]))
    meta$Cryoconite_Latitude[i] <- c(paste0("-", meta$Cryoconite_Latitude[i]))
  }
}

#Some of our cryoconite holes don't have specific coords so we'll use the glacier coordinates
#remove letters from glacier coord strings
meta$Glacier_Latitude <- as.numeric(str_sub(meta$Glacier_Latitude,1,nchar(meta$Glacier_Latitude)-1))
meta$Glacier_Longitude <- as.numeric(str_sub(meta$Glacier_Longitude,1,nchar(meta$Glacier_Longitude)-1))

glac_lat <- meta$Glacier_Latitude
glac_long <- meta$Glacier_Longitude

#get latitude of each sample
cryo_lat <- as.numeric(meta$Cryoconite_Latitude)
#get longitude of each sample
cryo_long <- as.numeric(meta$Cryoconite_Longitude)

#replace any missing cryoconite coords with those of it's glacier
for (j in 1:length(cryo_lat)){
  if (is.na(cryo_lat[j])){
    cryo_lat[j] <- glac_lat[j]
    cryo_long[j] <- glac_long[j]
  }
}

#put into matrix
long.lat <- as.data.frame(cbind(cryo_long, cryo_lat))
rownames(long.lat) = rownames(meta)

return(long.lat)

}

# #Test function
# phylo = ps
# res <- get_my_long_lat(ps)
```

RDA:Full
```{r}
#Function testing area
# phylo = ps
# perc = 0.5
# level = "Class"
# collin = 30
# abundance_class <- "total"
# do_my_rda_full(ps, 0.5, "Class", 30, "total")

do_my_rda_full <- function(phylo, perc, level, collin, abundance_class){
  
  #get community data
  varespec <- agg_my_counts(phylo, level)
  
  #transform count data
  varespech <- decostand(varespec, method = "hellinger")
  
  #get my metadata 
  varechem <- get_my_meta(phylo, perc)
  #trim species to match remaining metadata
  varespech_trim <- varespech[(rownames(varespech) %in% rownames(varechem)),]
  
  #perform initial RDA
  rda1 <- rda(varespech_trim ~., data=varechem)
  rda1
  
  #check significant of first model
  signif1 <- anova.cca(rda1)
  
  #plot model
  pdf(paste0("../../results/16S/graphs/RDA/16S-", abundance_class, "-first-full-RDA-plot.pdf"))
  plot(rda1, xlim=c(-1.5,2), ylim=c(-1,1.5), display=c("sp","cn","wa"))
  text(-1, 1, paste0("p= ", as.numeric(signif1$`Pr(>F)`)[1]))
  text(-1, 0.7, paste0("F= ", as.numeric(round(signif1$F[1], digits=4))))
  title(main=paste0("16S ", abundance_class, " Community First Full RDA"))
  dev.off()

  
  #plot correlation matrix of independent variables
  #let's explore multicollinearity with a correlation matrix
  res <- cor(varechem)
  
  #plot the correlations
  pdf(paste0("../../results/16S/graphs/16S-metadata-correlation-matrix.pdf"))
  cor_plot <- corrplot(res, type = "upper", order = "hclust", 
           tl.col = "black", tl.srt = 45)
  dev.off()
  
  #Get variance inflation factors of independent variables
  vif_res <- data.frame(vif.cca(rda1))
  
  #Remove variable with too much collinearity
  var_to_keep <- vector()
  for (i in 1:nrow(vif_res)){
    if (vif_res[i,] < collin){
      var_to_keep <- c(var_to_keep, rownames(vif_res)[i])
    }
  }
  varechem_reduce <- varechem[,names(varechem) %in% var_to_keep]
  
  #Now we'll do stepwise selection to find the remaining variables that best explain our data
  upr <- rda(varespech_trim ~ ., data = varechem_reduce) #model with all our variables
  lwr <- rda(varespech_trim ~ 1, data = varechem_reduce) #null model
  set.seed(1)
  #Stepwise selection via adjusted R
  mod <- ordiR2step(lwr, upr, trace = FALSE)
  mod 
  
  #check significant of final model
  signif2 <- anova.cca(mod)
  
  #plot model
  pdf(paste0("../../results/16S/graphs/RDA/16S-", abundance_class, "-final-full-RDA-plot.pdf"))
  plot(mod, xlim=c(-1.5,2), ylim=c(-1,1.5), display=c("sp","cn","wa"))
  text(-1, 1, paste0("p= ", as.numeric(signif2$`Pr(>F)`)[1]))
  text(-1, 0.7, paste0("F= ", as.numeric(round(signif2$F[1], digits=4))))
  title(main=paste0("16S ", abundance_class, " Community Final Full RDA"))
  dev.off()
}

```

Carry out RDAs
```{r}
do_my_rda_full(ps, 0.5, "Class", 30, "total")
do_my_rda_full(ps.rare, 0.5, "Class", 30, "rare")
do_my_rda_full(ps.abun, 0.5, "Class", 30, "abundant")
do_my_rda_full(ps.int, 0.5, "Class", 30, "intermediate")
```
