Rsqr=Rsqr, p.value=m.sum$parameters[4], N=N,
Samples=nrow(ASV.table), Richness=length(p.list),
Detect=d)
View(fitstats)
# Get confidence interval for predictions
freq.pred.ci <- binconf(freq.pred*nrow(ASV.table), nrow(ASV.table), alpha=0.05, method="wilson", return.df=TRUE)
# Get table of predictions
pred.df <- data.frame(metacomm_RA=p.list, frequency=freq.pred,
frequency_lowerCI=freq.pred.ci[,2],
frequency_upperCI=freq.pred.ci[,3]) %>%
unique()
# Get table of observed occupancy and abundance
obs.df = C.no0 %>%
rename(metacomm_RA = p, frequency=freq)
#add abundance classifications to obs.df
#obs.df$abun_class <- abun_class$Abundance
abun_class$ASV <- abun_class$ID
new.df <- merge(obs.df, abun_class, by=c("ASV"))
ggplot(data=new.df) +
geom_point(data=new.df, aes(x=log10(metacomm_RA), y=frequency, color=Abundance),
alpha=.2, size=2) +
geom_line(data=pred.df, aes(x=log10(metacomm_RA), y=frequency), color="black") +
geom_line(data=pred.df, aes(x=log10(metacomm_RA), y=frequency_lowerCI), linetype=2, color="black") +
geom_line(data=pred.df, aes(x=log10(metacomm_RA), y=frequency_upperCI), linetype=2, color="black") +
geom_text(data=fitstats, aes(label = paste("R^2 == ", round(Rsqr, 3))),
x=-4.9, y=0.75, size=4, parse=TRUE) +
geom_text(data=fitstats, aes(label = paste("italic(m) ==", round(m, 4))),
x=-4.9, y=0.68, size=4, parse=TRUE) +
labs(x="Log10 abundance in\nmetacommunity", y="Frequency detected") +
theme_bw() +
theme(axis.line = element_line(color="black"),
#legend.position = "none",
axis.title = element_text(size=14),
axis.text = element_text(size=12))+
ggtitle("18S Neutral Model Plot")
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
graphics.off()
#library(phyloseq)
library(Hmisc)
library(igraph)
#library(agricolae)
library(fdrtool)
library(vegan) #rarecurve function
library(dplyr)
library(ggpubr)
library(car) #levene test
library(plyr)
pro <- readRDS("../../results/16S/phylo-objects/16S-phyloseq-object-rarefied-decontam.rds")
euk <- readRDS("../../results/18S/phylo-objects/18S-phyloseq-object-rarefied.rds")
#Filter ASVs by percentage presence in samples to simplify the network
filter_me <- function(my_df, perc){
#remove ASVs present in less than 10% samples
df <- 1*(my_df>0) #presence/abundance df
pres_vec <- vector()
asv_vec <- vector()
for (k in 1:ncol(df)){  #for each ASV
pres <- as.numeric(colSums(df)[k])/nrow(df) #find the percentage of samples the ASV is present in
pres_vec <- c(pres_vec, pres)
asv_vec <- c(asv_vec, colnames(df)[k])
}
df_2 <- data.frame(ASV=asv_vec, Present=pres_vec) #df of percentage of samples asvs are present in
trim_me <- subset(df_2, df_2$Present >= perc) #only keep ASVs in >= 10% of samples (that's at least two samples)
#use ASV IDs to subset count table
asv_pres_trim <- my_df[, (colnames(my_df) %in% trim_me$ASV)]
return(asv_pres_trim)
}
#Function testing area
# phylo1 = pro
# phylo2 = euk
# # pole = "Arctic"
#
# my_ASVs_and_classifications <- network_data_prep(pro, euk)
# #asv table
# my_ASVs_and_classifications$asvs
# #classifications
# my_ASVs_and_classifications$class
network_data_prep <- function(phylo1, phylo2, perc){
#subset by pole
# ps1.pole <- subset_samples(phylo1, Pole== pole)
# ps2.pole <- subset_samples(phylo2, Pole== pole)
ps1.pole <- phylo1
ps2.pole <- phylo2
#make sure both datasets have the same sample sizes
#if pro is bigger than euk, cut pro to be same size as euk
#if pro is smaller than euk, cut euk to be same size as pro
if (min(sample_sums(ps1.pole)) > min(sample_sums(ps2.pole))){
ps1.pole = rarefy_even_depth(ps1.pole, rngseed=1, sample.size=min(sample_sums(ps2.pole)), replace=F)
} else if (min(sample_sums(ps1.pole)) < min(sample_sums(ps2.pole))){
ps2.pole = rarefy_even_depth(ps2.pole, rngseed=1, sample.size=min(sample_sums(ps1.pole)), replace=F)
}
#transform our count data into relative abundances
rel_abun1 = transform_sample_counts(ps1.pole, function(x) x / sum(x) )
rel_abun2 = transform_sample_counts(ps2.pole, function(x) x / sum(x) )
#get our ASV tables
asv_tab1 <- data.frame(t(otu_table(rel_abun1)), check.names=FALSE)
asv_tab2 <- data.frame(t(otu_table(rel_abun2)), check.names=FALSE)
#make ASV table row names the sample names
data1 <- data.frame(sample_data(rel_abun1))
data2 <- data.frame(sample_data(rel_abun2))
rownames(asv_tab1) <- data1$Name
rownames(asv_tab2) <- data2$Name
#only keep samples that are the same across the datasets
asv_tab1.trim <- asv_tab1[rownames(asv_tab1) %in% rownames(asv_tab2),]
asv_tab2.trim <- asv_tab2[rownames(asv_tab2) %in% rownames(asv_tab1.trim),]
#order the rows
new_df1 <- asv_tab1.trim[ order(row.names(asv_tab1.trim)), ]
new_df2 <- asv_tab2.trim[ order(row.names(asv_tab2.trim)), ]
#seperate ASVs by abundance
rare1 <- new_df1[,colSums(new_df1)/nrow(new_df1)< 0.00001]
abundant1 <- new_df1[,colSums(new_df1)/nrow(new_df1)>0.0005]
intermediate1 <- new_df1[,colSums(new_df1)/nrow(new_df1)>=0.00001 & colSums(new_df1)/nrow(new_df1)<=0.0005]
rare2 <- new_df2[,colSums(new_df2)/nrow(new_df2)< 0.00001]
abundant2 <- new_df2[,colSums(new_df2)/nrow(new_df2)>0.0005]
intermediate2 <- new_df2[,colSums(new_df2)/nrow(new_df2)>=0.00001 & colSums(new_df2)/nrow(new_df2)<=0.0005]
#create a dataframe with ASV IDs and their abundance classification
abundance_class_df <- data.frame(ID = c(names(rare1), names(abundant1), names(intermediate1), names(rare2), names(abundant2), names(intermediate2)), Class=c(rep("Rare", ncol(rare1)), rep("Abundant", ncol(abundant1)), rep("Intermediate", ncol(intermediate1)), rep("Rare", ncol(rare2)), rep("Abundant", ncol(abundant2)), rep("Intermediate", ncol(intermediate2))), Kingdom=c(rep("Prokaryote", ncol(rare1)+ncol(abundant1)+ncol(intermediate1)), rep("Eukaryote", ncol(rare2)+ncol(abundant2)+ncol(intermediate2))))
#filter ASVs to those present in at least % of samples
pro_filter <- filter_me(new_df1, perc)
euk_filter <- filter_me(new_df2, perc)
#finally bind out dataframes together
pro_and_euk <- cbind(pro_filter, euk_filter)
#list for returning data
newList <- list("class" = abundance_class_df, "asvs" = pro_and_euk)
return(newList)
}
#Function testing area
phylo1 = pro
phylo2 = euk
perc=0.05
get_my_network <- function(phylo1, phylo2, perc){
set.seed(666)
#get our asv table
output <- network_data_prep(phylo1, phylo2, perc)
asv_tab <- output$asvs
#find the spearmans correlations between asvs
cor_analysis <-rcorr(as.matrix(asv_tab),type="spearman")
#assign the matrix of correlations and the p-values to r and p, respectively
cor_r<-cor_analysis$r
cor_p<-cor_analysis$P
#matrix diagonals - apply the value 1 to the diagonal values of the p matrix (instead of NA as they were before)
diag(cor_p)<-1
#make p-values matrix into vector
cor_pp<-as.vector(cor_p)
#how many of our p values are < 0.01
length(cor_pp[cor_pp > 0 & cor_pp < 0.01])
#estimate false discovery rates
cor_qvalue<-fdrtool(cor_pp,statistic="pvalue")
#extract the vector with q-values (density based falese discovery rates)
cor_q<-cor_qvalue$qval
#how many of our p values are < 0.01
length(cor_q[cor_q > 0 & cor_q < 0.01])
#what are our unique adjusted p values?
unique(cor_q) #lots of them! Essentially we don't want to see 1 NaN here (this means we have no significant adjusted p values)
#create a matrix with the q-values with the same number of rows and columns as p-values matrix
cor_q<-matrix(cor_q,nrow(cor_p),ncol(cor_p))
#make any value of q > 0.01 a 0
cor_q[cor_q>0.01]<-0
#make any value <= 0.01 & greater than 0 = 1
cor_q[cor_q<=0.01&cor_q>0]<-1
#let's look at the range of correlation coefficients
hist(cor_r)
#are there any with coefficients > | 0.6|?
length(cor_r[cor_r < -0.6]) #there are 288 negative correlation coefficients
length(cor_r[cor_r > 0.6]) #there 60567 positive correlation coefficients
#change the value of any correlation coefficients < | 0.6 | to 0
#cor_r[abs(cor_r)<0.6]<-0
cor_r[(cor_r)<0.6]<-0
#multiple the correlation coefficients by q-values so that insignificant coefficients become 0
cor<-cor_r*cor_q
#are there any with coefficients > | 0.6| after removing non-significant correlations?
length(cor[cor < -0.6])
length(cor[cor > 0.6])
#create igraph graph from adjacency matrix
cor_g <- graph.adjacency(cor, weighted=TRUE, mode="undirected")
#simplify the graph so it does not contain loops or multiple edges
cor_g <- simplify(cor_g)
#delete vertices from the graph
cor_g<-delete.vertices(cor_g,names(degree(cor_g)[degree(cor_g)==0]))
#export graph
write.graph(cor_g,"../../results/16S/network-analysis/16S-18S-network.gml", format="gml")
write.graph(cor_g,"../../results/18S/network-analysis/16S-18S-network.gml", format="gml")
return(cor_g)
}
#Function testing area
#my_graph <- get_my_network(pro, euk, 0.20)
# #Function testing area
# phylo1 = pro
# phylo2 = euk
# perc=0.05
#
# node_df <-node_level_properties(pro, euk, 0.05)
node_level_properties <- function(phylo1, phylo2, perc){
output <- network_data_prep(phylo1, phylo2, perc)
cor_g <- get_my_network(phylo1, phylo2, perc)
#get the info on our classifications
class_data <- output$class
rare <- subset(class_data, (class_data$Class == "Rare"))
abundant <- subset(class_data, (class_data$Class == "Abundant"))
intermediate <- subset(class_data, (class_data$Class == "Intermediate"))
#create a dataframe with 5 columns and a row for each node (ASV)
df<-as.data.frame(matrix(NA,ncol=5,nrow=length(degree(cor_g))))
#make ASV IDs row names of df
rownames(df)<-names(degree(cor_g))
#name the colums the node-level topological features
colnames(df)<-c("degree","betweenness","closeness","eigenvector","category")
#categorise the ASVs as rare, abundant or intermediate
df[intersect(names(degree(cor_g)),rare$ID),5]<-"rare"
df[intersect(names(degree(cor_g)),abundant$ID),5]<-"abundant"
df[intersect(names(degree(cor_g)),intermediate$ID),5]<-"intermediate"
#get betweenness
btw<-betweenness(cor_g)
#get closeness centrality
cls<-closeness(cor_g)
#get eigenvector centrality
egv<-evcent(cor_g)
#put the topological features into the dataframe
df[,1]<-degree(cor_g)
df[,2]<-btw
df[,3]<-cls
df[,4]<-egv$vector
write.csv(df, "../../results/16S/network-analysis/16S-18S-node-level-properties.csv")
write.csv(df, "../../results/18S/network-analysis/16S-18S-node-level-properties.csv")
return(df)
}
#Function testing area
# phylo1 = pro
# phylo2 = euk
# perc = 0.05
network_tax <- function(phylo1, phylo2, perc){
df <- node_level_properties(phylo1, phylo2, perc)
#get taxa info of keystone ASVs
taxonomy1 <- data.frame(tax_table(phylo1))
taxonomy2 <- data.frame(tax_table(phylo2))
taxonomy <- rbind(taxonomy1, taxonomy2)
network_taxa <- subset(taxonomy, rownames(taxonomy) %in% rownames(df))
write.csv(network_taxa, "../../results/16S/network-analysis/16S-18S-taxa.csv")
write.csv(network_taxa, "../../results/18S/network-analysis/16S-18S-taxa.csv")
return(network_taxa)
}
# #Function testing area
# phylo1 = pro
# phylo2 = euk
# perc=0.05
#
# net_df <- network_level_properties(pro, euk, 0.05)
network_level_properties <- function(phylo1, phylo2, perc){
cor_g <- get_my_network(phylo1, phylo2, perc)
df <- node_level_properties(phylo1, phylo2, perc)
#subset the node level dataframe by rare ASVs
a<-subset(df,category=="rare")
g_ra<-induced_subgraph(cor_g,rownames(a))
#abundant
a<-subset(df,category=="abundant")
g_abd<-induced_subgraph(cor_g,rownames(a))
#intermediate
a<-subset(df,category=="intermediate")
g_int<-induced_subgraph(cor_g,rownames(a))
#number of nodes (a.k.a. vertices/ASVs)
gorder(cor_g) #total = 1996
gorder(g_ra) #rare = 93
gorder(g_abd) #abundant = 334
gorder(g_int) #intermediate = 1569
#number of edges
gsize(cor_g) #total = 57391
gsize(g_ra) #rare = 122
gsize(g_abd) #abundant = 4702
gsize(g_int) #intermediate = 33182
#mean node degree (number of edges), clustering coefficient (probability that the adjacent vertices of a vertex   are connected), average path length, modularity, density, network diameter
#create a dataframe to store out network features
net_df<-as.data.frame(matrix(NA,ncol=8,nrow=4))
net_df[1,]<-c(mean(degree(cor_g)),transitivity(cor_g),average.path.length(cor_g),
graph.density(cor_g),diameter(cor_g),modularity(walktrap.community(cor_g)), gorder(cor_g), gsize(cor_g))
net_df[2,]<-c(mean(degree(g_abd)),transitivity(g_abd),average.path.length(g_abd),
graph.density(g_abd),diameter(g_abd),modularity(walktrap.community(g_abd)), gorder(g_abd), gsize(g_abd))
net_df[3,]<-c(mean(degree(g_ra)),transitivity(g_ra),average.path.length(g_ra),
graph.density(g_ra),diameter(g_ra),modularity(walktrap.community(g_ra)), gorder(g_ra), gsize(g_ra))
net_df[4,]<-c(mean(degree(g_int)),transitivity(g_int),average.path.length(g_int),
graph.density(g_int),diameter(g_int),modularity(walktrap.community(g_int)), gorder(g_int), gsize(g_int))
colnames(net_df)<-c("AveDegree","ClustCoef","AvePathLen","Density","Diameter","Modularity", "Nodes", "Edges")
rownames(net_df)<-c("Total", "Abundant","Rare","Intermediate")
write.csv(net_df, "../../results/16S/network-analysis/16S-18S-network-level-properties.csv")
write.csv(net_df, "../../results/18S/network-analysis/16S-18S-network-level-properties.csv")
return(net_df)
}
# #Function testing area
# phylo1 = pro
# phylo2 = euk
# perc = 0.05
# res <- connections_between_communities(pro, euk, 0.05)
connections_between_communities<- function(phylo1, phylo2, perc){
cor_g <- get_my_network(phylo1, phylo2, perc)
output <- network_data_prep(phylo1, phylo2, perc)
#get the info on our classifications
class_data <- output$class
rare <- subset(class_data, (class_data$Class == "Rare"))
abundant <- subset(class_data, (class_data$Class == "Abundant"))
intermediate <- subset(class_data, (class_data$Class == "Intermediate"))
#extract the adjacency matric from the simplified igraph
mat <- as.data.frame(as_adjacency_matrix(cor_g, sparse = FALSE))
#make a dataframe with all the pairs of ASVs with significant correlations
x <- tidyr::gather(mat) #gather data
x$ASV_Two <- rep(colnames(mat), nrow(mat)) #add second asv
x[x==0] <- NA #set 0 to NA
x2<-x[complete.cases(x),]#remove rows with NA
x2 <- subset(x2, select = -c(value)) #remove value column
colnames(x2) <- c("ASV_One", "ASV_Two") #rename columns
#this leaves us with repeat pairs so we need to remove them
#remove rows that have the repeated pairs of ASVs
#create a new dataframe with var 1 as ASV One and var2 as ASV Two
dat <- data.frame(var1 = x2$ASV_One,var2 = x2$ASV_Two, cor = rep(1, nrow(x2)))
#remove any rows that have the same two ASVs as another row
dat1 <- dat[!duplicated(apply(dat,1,function(x) paste(sort(x),collapse=''))),]
#remove cor column
dat1 <- dat1[,-c(3)]
#get abundance of ASV One
for (i in 1:nrow(dat1)){
if(dat1$var1[i] %in% rare$ID){
dat1$var3[i] <- "rare"
} else if(dat1$var1[i] %in% abundant$ID){
dat1$var3[i] <- "abundant"
} else {
dat1$var3[i] <- "intermediate"
}
}
#get abundance of ASV Two
for (i in 1:nrow(dat1)){
if(dat1$var2[i] %in% rare$ID){
dat1$var4[i] <- "rare"
} else if(dat1$var2[i] %in% abundant$ID){
dat1$var4[i] <- "abundant"
} else {
dat1$var4[i] <- "intermediate"
}
}
#rename the columns
colnames(dat1) <- c("ASV_One", "ASV_Two", "Abund_One", "Abund_Two")
#table the data
community_links_df <- data.frame(table(dat1[,3:4]))
write.csv(community_links_df, "../../results/16S/network-analysis/16S-18S-community-connections.csv")
write.csv(community_links_df, "../../results/18S/network-analysis/16S-18S-community-connections.csv")
}
#Function testing area
# phylo1 = pro
# phylo2 = euk
# perc  = 0.05
# signif_dif_nodes(pro, euk, 0.05)
signif_dif_nodes <- function(phylo1, phylo2, perc){
df <- node_level_properties(phylo1, phylo2, perc)
#Degree
# Perform pairwise comparisons
compare_means(degree ~ category,  data = df)
# Visualize: Specify the comparisons you want
my_comparisons <- list( c("abundant", "intermediate"), c("intermediate", "rare"), c("abundant", "rare") )
p2 <- ggboxplot(df, x = "category", y = "degree",
color = "category", palette = "jco")+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 300)     # Add global p-value
pdf("../../results/16S/network-analysis/16S-18S-abundance-class-degree-boxplot2.pdf")
print(p2)
dev.off()
pdf("../../results/18S/network-analysis/16S-18S-abundance-class-degree-boxplot2.pdf")
print(p2)
dev.off()
#Between
# Perorm pairwise comparisons
compare_means(betweenness ~ category,  data = df)
# Visualize: Specify the comparisons you want
my_comparisons <- list( c("abundant", "intermediate"), c("intermediate", "rare"), c("abundant", "rare") )
p3 <- ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 600000)# Add global p-value
pdf("../../results/16S/network-analysis/16S-18S-abundance-class-betweenness-boxplot.pdf")
print(p3)
dev.off()
pdf("../../results/18S/network-analysis/16S-18S-abundance-class-betweenness-boxplot.pdf")
print(p3)
dev.off()
#Closeness
# Perorm pairwise comparisons
compare_means(closeness ~ category,  data = df)
# Visualize: Specify the comparisons you want
my_comparisons <- list( c("abundant", "intermediate"), c("intermediate", "rare"), c("abundant", "rare") )
p4 <- ggboxplot(df, x = "category", y = "closeness",
color = "category", palette = "jco")+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 0.0003)# Add global p-value
pdf("../../results/16S/network-analysis/16S-18S-abundance-class-closeness-boxplot.pdf")
print(p4)
dev.off()
pdf("../../results/18S/network-analysis/16S-18S-abundance-class-closeness-boxplot.pdf")
print(p4)
dev.off()
#Eigenvector
# Perform pairwise comparisons
compare_means(eigenvector ~ category,  data = df)
# Visualize: Specify the comparisons you want
my_comparisons <- list( c("abundant", "intermediate"), c("intermediate", "rare"), c("abundant", "rare") )
p5 <- ggboxplot(df, x = "category", y = "eigenvector",
color = "category", palette = "jco")+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y=1.5)# Add global p-value
pdf("../../results/16S/network-analysis/16S-18S-abundance-class-eigenvector-boxplot.pdf")
print(p5)
dev.off()
pdf("../../results/18S/network-analysis/16S-18S-abundance-class-eigenvector-boxplot.pdf")
print(p5)
dev.off()
}
phylo1 = pro
phylo2 = euk
perc  = 0.05
df <- node_level_properties(phylo1, phylo2, perc)
#Between
# Perorm pairwise comparisons
compare_means(betweenness ~ category,  data = df)
# Visualize: Specify the comparisons you want
my_comparisons <- list( c("abundant", "intermediate"), c("intermediate", "rare"), c("abundant", "rare") )
ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 600000)# Add global p-value
ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
stat_compare_means(comparisons = my_comparisons)#+ #
?stat_compare_means
ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 60000)# Add global p-value
ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
stat_compare_means(comparisons = my_comparisons, label.y = 60000)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 60000)# Add global p-value
ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
ylim(0, 65000)+
stat_compare_means(comparisons = my_comparisons, label.y = 60000)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 60000)#
ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
ylim(0, 20000)+
stat_compare_means(comparisons = my_comparisons, label.y = 10000)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 10000)# Add global p-value
ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
ylim(0, 10000)+
stat_compare_means(comparisons = my_comparisons, label.y = 9000)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 9000)# Add global p-value
ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
ylim(0, 9000)+
stat_compare_means(comparisons = my_comparisons, label.y = 8000)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 8000)# Add global p-value
ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
ylim(0, 5000)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 4000)# Add global p-value
p3 <- ggboxplot(df, x = "category", y = "betweenness",
color = "category", palette = "jco", outlier.shape = NULL)+
ylim(0, 5000)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y = 4000)# Add global p-value
pdf("../../results/16S/network-analysis/16S-18S-abundance-class-betweenness-boxplot.pdf")
print(p3)
dev.off()
pdf("../../results/18S/network-analysis/16S-18S-abundance-class-betweenness-boxplot.pdf")
print(p3)
dev.off()
ggboxplot(df, x = "category", y = "eigenvector",
color = "category", palette = "jco")+
ylim(0, 0.5)
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y=0.4)# Add global p-value
ggboxplot(df, x = "category", y = "eigenvector",
color = "category", palette = "jco")+
ylim(0, 0.5)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y=0.4)# Add global p-value
ggboxplot(df, x = "category", y = "eigenvector",
color = "category", palette = "jco")+
ylim(0, 0.2)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y=0.1)# Add global p-value
ggboxplot(df, x = "category", y = "eigenvector",
color = "category", palette = "jco")+
ylim(0, 0.05)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y=0.04)# Add global p-value
ggboxplot(df, x = "category", y = "eigenvector",
color = "category", palette = "jco")+
ylim(0, 0.02)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y=0.01)# Add global p-value
ggboxplot(df, x = "category", y = "eigenvector",
color = "category", palette = "jco")+
ylim(0, 0.01)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y=0.005)# Add global p-value
p5 <- ggboxplot(df, x = "category", y = "eigenvector",
color = "category", palette = "jco")+
ylim(0, 0.01)+
stat_compare_means(comparisons = my_comparisons)+ # Add pairwise comparisons p-value
stat_compare_means(label.y=0.005)# Add global p-value
pdf("../../results/16S/network-analysis/16S-18S-abundance-class-eigenvector-boxplot.pdf")
print(p5)
dev.off()
pdf("../../results/18S/network-analysis/16S-18S-abundance-class-eigenvector-boxplot.pdf")
print(p5)
dev.off()
